import asyncio
import re
import time
import traceback
from collections.abc import AsyncGenerator

from astrbot.core import logger
from astrbot.core.agent.message import Message
from astrbot.core.agent.runners.tool_loop_agent_runner import ToolLoopAgentRunner
from astrbot.core.astr_agent_context import AstrAgentContext
from astrbot.core.message.components import BaseMessageComponent, Json, Plain
from astrbot.core.message.message_event_result import (
    MessageChain,
    MessageEventResult,
    ResultContentType,
)
from astrbot.core.provider.entities import LLMResponse
from astrbot.core.provider.provider import TTSProvider

AgentRunner = ToolLoopAgentRunner[AstrAgentContext]


async def run_agent(
    agent_runner: AgentRunner,
    max_step: int = 30,
    show_tool_use: bool = True,
    stream_to_general: bool = False,
    show_reasoning: bool = False,
) -> AsyncGenerator[MessageChain | None, None]:
    step_idx = 0
    astr_event = agent_runner.run_context.context.event
    while step_idx < max_step + 1:
        step_idx += 1

        if step_idx == max_step + 1:
            logger.warning(
                f"Agent reached max steps ({max_step}), forcing a final response."
            )
            if not agent_runner.done():
                # æ‹”æ‰æ‰€æœ‰å·¥å…·
                if agent_runner.req:
                    agent_runner.req.func_tool = None
                # æ³¨å…¥æç¤ºè¯
                agent_runner.run_context.messages.append(
                    Message(
                        role="user",
                        content="å·¥å…·è°ƒç”¨æ¬¡æ•°å·²è¾¾åˆ°ä¸Šé™ï¼Œè¯·åœæ­¢ä½¿ç”¨å·¥å…·ï¼Œå¹¶æ ¹æ®å·²ç»æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼Œå¯¹ä½ çš„ä»»åŠ¡å’Œå‘ç°è¿›è¡Œæ€»ç»“ï¼Œç„¶åç›´æ¥å›å¤ç”¨æˆ·ã€‚",
                    )
                )

        try:
            async for resp in agent_runner.step():
                if astr_event.is_stopped():
                    return
                if resp.type == "tool_call_result":
                    msg_chain = resp.data["chain"]
                    if msg_chain.type == "tool_direct_result":
                        # tool_direct_result ç”¨äºæ ‡è®° llm tool éœ€è¦ç›´æ¥å‘é€ç»™ç”¨æˆ·çš„å†…å®¹
                        await astr_event.send(msg_chain)
                        continue
                    if astr_event.get_platform_id() == "webchat":
                        await astr_event.send(msg_chain)
                    # å¯¹äºå…¶ä»–æƒ…å†µï¼Œæš‚æ—¶å…ˆä¸å¤„ç†
                    continue
                elif resp.type == "tool_call":
                    if agent_runner.streaming:
                        # ç”¨æ¥æ ‡è®°æµå¼å“åº”éœ€è¦åˆ†èŠ‚
                        yield MessageChain(chain=[], type="break")

                    if astr_event.get_platform_name() == "webchat":
                        await astr_event.send(resp.data["chain"])
                    elif show_tool_use:
                        json_comp = resp.data["chain"].chain[0]
                        if isinstance(json_comp, Json):
                            m = f"ğŸ”¨ è°ƒç”¨å·¥å…·: {json_comp.data.get('name')}"
                        else:
                            m = "ğŸ”¨ è°ƒç”¨å·¥å…·..."
                        chain = MessageChain(type="tool_call").message(m)
                        await astr_event.send(chain)
                    continue

                if stream_to_general and resp.type == "streaming_delta":
                    continue

                if stream_to_general or not agent_runner.streaming:
                    content_typ = (
                        ResultContentType.LLM_RESULT
                        if resp.type == "llm_result"
                        else ResultContentType.GENERAL_RESULT
                    )
                    astr_event.set_result(
                        MessageEventResult(
                            chain=resp.data["chain"].chain,
                            result_content_type=content_typ,
                        ),
                    )
                    yield
                    astr_event.clear_result()
                elif resp.type == "streaming_delta":
                    chain = resp.data["chain"]
                    if chain.type == "reasoning" and not show_reasoning:
                        # display the reasoning content only when configured
                        continue
                    yield resp.data["chain"]  # MessageChain
            if agent_runner.done():
                # send agent stats to webchat
                if astr_event.get_platform_name() == "webchat":
                    await astr_event.send(
                        MessageChain(
                            type="agent_stats",
                            chain=[Json(data=agent_runner.stats.to_dict())],
                        )
                    )

                break

        except Exception as e:
            logger.error(traceback.format_exc())

            err_msg = f"\n\nAstrBot è¯·æ±‚å¤±è´¥ã€‚\né”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯ä¿¡æ¯: {e!s}\n\nè¯·åœ¨å¹³å°æ—¥å¿—æŸ¥çœ‹å’Œåˆ†äº«é”™è¯¯è¯¦æƒ…ã€‚\n"

            error_llm_response = LLMResponse(
                role="err",
                completion_text=err_msg,
            )
            try:
                await agent_runner.agent_hooks.on_agent_done(
                    agent_runner.run_context, error_llm_response
                )
            except Exception:
                logger.exception("Error in on_agent_done hook")

            if agent_runner.streaming:
                yield MessageChain().message(err_msg)
            else:
                astr_event.set_result(MessageEventResult().message(err_msg))
            return


async def run_live_agent(
    agent_runner: AgentRunner,
    tts_provider: TTSProvider | None = None,
    max_step: int = 30,
    show_tool_use: bool = True,
    show_reasoning: bool = False,
) -> AsyncGenerator[MessageChain | None, None]:
    """Live Mode çš„ Agent è¿è¡Œå™¨ï¼Œæ”¯æŒæµå¼ TTS

    Args:
        agent_runner: Agent è¿è¡Œå™¨
        tts_provider: TTS Provider å®ä¾‹
        max_step: æœ€å¤§æ­¥æ•°
        show_tool_use: æ˜¯å¦æ˜¾ç¤ºå·¥å…·ä½¿ç”¨
        show_reasoning: æ˜¯å¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹

    Yields:
        MessageChain: åŒ…å«æ–‡æœ¬æˆ–éŸ³é¢‘æ•°æ®çš„æ¶ˆæ¯é“¾
    """
    # å¦‚æœæ²¡æœ‰ TTS Providerï¼Œç›´æ¥å‘é€æ–‡æœ¬
    if not tts_provider:
        async for chain in run_agent(
            agent_runner,
            max_step=max_step,
            show_tool_use=show_tool_use,
            stream_to_general=False,
            show_reasoning=show_reasoning,
        ):
            yield chain
        return

    support_stream = tts_provider.support_stream()
    if support_stream:
        logger.info("[Live Agent] ä½¿ç”¨æµå¼ TTSï¼ˆåŸç”Ÿæ”¯æŒ get_audio_streamï¼‰")
    else:
        logger.info(
            f"[Live Agent] ä½¿ç”¨ TTSï¼ˆ{tts_provider.meta().type} "
            "ä½¿ç”¨ get_audioï¼Œå°†æŒ‰å¥å­åˆ†å—ç”ŸæˆéŸ³é¢‘ï¼‰"
        )

    # ç»Ÿè®¡æ•°æ®åˆå§‹åŒ–
    tts_start_time = time.time()
    tts_first_frame_time = 0.0
    first_chunk_received = False

    # åˆ›å»ºé˜Ÿåˆ—
    text_queue: asyncio.Queue[str | None] = asyncio.Queue()
    # audio_queue stored bytes or (text, bytes)
    audio_queue: asyncio.Queue[bytes | tuple[str, bytes] | None] = asyncio.Queue()

    # 1. å¯åŠ¨ Agent Feeder ä»»åŠ¡ï¼šè´Ÿè´£è¿è¡Œ Agent å¹¶å°†æ–‡æœ¬åˆ†å¥å–‚ç»™ text_queue
    feeder_task = asyncio.create_task(
        _run_agent_feeder(
            agent_runner, text_queue, max_step, show_tool_use, show_reasoning
        )
    )

    # 2. å¯åŠ¨ TTS ä»»åŠ¡ï¼šè´Ÿè´£ä» text_queue è¯»å–æ–‡æœ¬å¹¶ç”ŸæˆéŸ³é¢‘åˆ° audio_queue
    if support_stream:
        tts_task = asyncio.create_task(
            _safe_tts_stream_wrapper(tts_provider, text_queue, audio_queue)
        )
    else:
        tts_task = asyncio.create_task(
            _simulated_stream_tts(tts_provider, text_queue, audio_queue)
        )

    # 3. ä¸»å¾ªç¯ï¼šä» audio_queue è¯»å–éŸ³é¢‘å¹¶ yield
    try:
        while True:
            queue_item = await audio_queue.get()

            if queue_item is None:
                break

            text = None
            if isinstance(queue_item, tuple):
                text, audio_data = queue_item
            else:
                audio_data = queue_item

            if not first_chunk_received:
                # è®°å½•é¦–å¸§å»¶è¿Ÿï¼ˆä»å¼€å§‹å¤„ç†åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ªéŸ³é¢‘å—ï¼‰
                tts_first_frame_time = time.time() - tts_start_time
                first_chunk_received = True

            # å°†éŸ³é¢‘æ•°æ®å°è£…ä¸º MessageChain
            import base64

            audio_b64 = base64.b64encode(audio_data).decode("utf-8")
            comps: list[BaseMessageComponent] = [Plain(audio_b64)]
            if text:
                comps.append(Json(data={"text": text}))
            chain = MessageChain(chain=comps, type="audio_chunk")
            yield chain

    except Exception as e:
        logger.error(f"[Live Agent] è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
    finally:
        # æ¸…ç†ä»»åŠ¡
        if not feeder_task.done():
            feeder_task.cancel()
        if not tts_task.done():
            tts_task.cancel()

        # ç¡®ä¿é˜Ÿåˆ—è¢«æ¶ˆè´¹
        pass

    tts_end_time = time.time()

    # å‘é€ TTS ç»Ÿè®¡ä¿¡æ¯
    try:
        astr_event = agent_runner.run_context.context.event
        if astr_event.get_platform_name() == "webchat":
            tts_duration = tts_end_time - tts_start_time
            await astr_event.send(
                MessageChain(
                    type="tts_stats",
                    chain=[
                        Json(
                            data={
                                "tts_total_time": tts_duration,
                                "tts_first_frame_time": tts_first_frame_time,
                                "tts": tts_provider.meta().type,
                                "chat_model": agent_runner.provider.get_model(),
                            }
                        )
                    ],
                )
            )
    except Exception as e:
        logger.error(f"å‘é€ TTS ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


async def _run_agent_feeder(
    agent_runner: AgentRunner,
    text_queue: asyncio.Queue,
    max_step: int,
    show_tool_use: bool,
    show_reasoning: bool,
):
    """è¿è¡Œ Agent å¹¶å°†æ–‡æœ¬è¾“å‡ºåˆ†å¥æ”¾å…¥é˜Ÿåˆ—"""
    buffer = ""
    try:
        async for chain in run_agent(
            agent_runner,
            max_step=max_step,
            show_tool_use=show_tool_use,
            stream_to_general=False,
            show_reasoning=show_reasoning,
        ):
            if chain is None:
                continue

            # æå–æ–‡æœ¬
            text = chain.get_plain_text()
            if text:
                buffer += text

                # åˆ†å¥é€»è¾‘ï¼šåŒ¹é…æ ‡ç‚¹ç¬¦å·
                # r"([.ã€‚!ï¼?ï¼Ÿ\n]+)" ä¼šä¿ç•™åˆ†éš”ç¬¦
                parts = re.split(r"([.ã€‚!ï¼?ï¼Ÿ\n]+)", buffer)

                if len(parts) > 1:
                    # å¤„ç†å®Œæ•´çš„å¥å­
                    # range step 2 å› ä¸º split åæ˜¯ [text, delim, text, delim, ...]
                    temp_buffer = ""
                    for i in range(0, len(parts) - 1, 2):
                        sentence = parts[i]
                        delim = parts[i + 1]
                        full_sentence = sentence + delim
                        temp_buffer += full_sentence

                        if len(temp_buffer) >= 10:
                            if temp_buffer.strip():
                                logger.info(f"[Live Agent Feeder] åˆ†å¥: {temp_buffer}")
                                await text_queue.put(temp_buffer)
                            temp_buffer = ""

                    # æ›´æ–° buffer ä¸ºå‰©ä½™éƒ¨åˆ†
                    buffer = temp_buffer + parts[-1]

        # å¤„ç†å‰©ä½™ buffer
        if buffer.strip():
            await text_queue.put(buffer)

    except Exception as e:
        logger.error(f"[Live Agent Feeder] Error: {e}", exc_info=True)
    finally:
        # å‘é€ç»“æŸä¿¡å·
        await text_queue.put(None)


async def _safe_tts_stream_wrapper(
    tts_provider: TTSProvider,
    text_queue: asyncio.Queue[str | None],
    audio_queue: "asyncio.Queue[bytes | tuple[str, bytes] | None]",
):
    """åŒ…è£…åŸç”Ÿæµå¼ TTS ç¡®ä¿å¼‚å¸¸å¤„ç†å’Œé˜Ÿåˆ—å…³é—­"""
    try:
        await tts_provider.get_audio_stream(text_queue, audio_queue)
    except Exception as e:
        logger.error(f"[Live TTS Stream] Error: {e}", exc_info=True)
    finally:
        await audio_queue.put(None)


async def _simulated_stream_tts(
    tts_provider: TTSProvider,
    text_queue: asyncio.Queue[str | None],
    audio_queue: "asyncio.Queue[bytes | tuple[str, bytes] | None]",
):
    """æ¨¡æ‹Ÿæµå¼ TTS åˆ†å¥ç”ŸæˆéŸ³é¢‘"""
    try:
        while True:
            text = await text_queue.get()
            if text is None:
                break

            try:
                audio_path = await tts_provider.get_audio(text)

                if audio_path:
                    with open(audio_path, "rb") as f:
                        audio_data = f.read()
                    await audio_queue.put((text, audio_data))
            except Exception as e:
                logger.error(
                    f"[Live TTS Simulated] Error processing text '{text[:20]}...': {e}"
                )
                # ç»§ç»­å¤„ç†ä¸‹ä¸€å¥

    except Exception as e:
        logger.error(f"[Live TTS Simulated] Critical Error: {e}", exc_info=True)
    finally:
        await audio_queue.put(None)
